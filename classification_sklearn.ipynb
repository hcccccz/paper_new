{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MeCab\n",
    "import ipadic\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torcheval.metrics.classification import BinaryRecall\n",
    "import torch\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class Feature_extractor:\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        self.data = pd.read_csv(data_path)\n",
    "\n",
    "        self.save_folder = \"features\"\n",
    "        self.features = {}\n",
    "\n",
    "    def date_feature(self):\n",
    "        dates = self.data[\"レビュー登録日時\"].to_numpy()\n",
    "        data_format = \"%Y-%m-%d %H:%M\"\n",
    "        end_day = datetime.strptime(\"2019-12-31 23:59\",data_format)\n",
    "        self.features[\"df\"] = [(end_day - datetime.strptime(date,data_format)).days for date in dates]\n",
    "\n",
    "    def is_title(self):\n",
    "        self.features[\"it\"] = self.data[\"レビュータイトル\"].isnull().to_numpy().astype(int)\n",
    "\n",
    "    def is_mokuteki(self):\n",
    "        self.features[\"im\"] = self.data[\"目的\"].isnull().to_numpy().astype(int)\n",
    "\n",
    "    def is_ti(self):\n",
    "        self.features[\"itsu\"] = self.data[\"使い道\"].isnull().to_numpy().astype(int)\n",
    "\n",
    "    def is_hin(self):\n",
    "        self.features[\"ih\"] = self.data[\"頻度\"].isnull().to_numpy().astype(int)\n",
    "\n",
    "    def title_wc(self):\n",
    "        self.tc = []\n",
    "        wakati = MeCab.Tagger(\"-Owakati\")\n",
    "        file_name = \"title_count.txt\"\n",
    "        if file_name not in os.listdir(self.save_folder):\n",
    "            review = self.data[\"レビュータイトル\"].to_numpy()\n",
    "            for line in tqdm(review):\n",
    "                if line is np.nan:\n",
    "                    out = 0\n",
    "                else:\n",
    "                    out = len(wakati.parse(line).split())\n",
    "                self.tc.append(out)\n",
    "            with open(os.path.join(self.save_folder,file_name), \"w\") as file:\n",
    "                for line in self.tc:\n",
    "                    file.write(str(line))\n",
    "                    file.write(\"\\n\")\n",
    "        else:\n",
    "            with open(os.path.join(self.save_folder,file_name), \"r\") as file:\n",
    "                self.tc = [int(line.replace(\"\\n\", \"\")) for line in file.readlines()]\n",
    "\n",
    "        self.features[\"tc\"] = self.tc\n",
    "\n",
    "    def word_count(self):\n",
    "        self.wc = []\n",
    "        wakati = MeCab.Tagger(\"-Owakati\")\n",
    "        file_name = \"word_count.txt\"\n",
    "        if file_name not in os.listdir(self.save_folder):\n",
    "            with open(os.path.join(self.save_folder,file_name), \"w\") as file:\n",
    "                review = self.data[\"レビュー内容\"].to_numpy()\n",
    "                for line in tqdm(review):\n",
    "                    out = len(wakati.parse(line).split())\n",
    "                    print(out)\n",
    "                    file.write(str(out))\n",
    "                    file.write(\"\\n\")\n",
    "                    self.wc.append(out)\n",
    "        else:\n",
    "            with open(os.path.join(self.save_folder,file_name), \"r\") as file:\n",
    "                self.wc = [int(line.replace(\"\\n\", \"\")) for line in file.readlines()]\n",
    "\n",
    "        self.features[\"wc\"] = self.wc\n",
    "\n",
    "    def score(self):\n",
    "        self.features['score'] = self.data[\"評価ポイント\"].to_numpy()\n",
    "        # self.features['score'] = s(self.data['評価ポイント'] == 1).astype(int).to_numpy()\n",
    "    def encode_mokuteki(self):\n",
    "        return pd.get_dummies(self.data[\"目的\"]).astype(int)\n",
    "\n",
    "    def encode_hindo(self):\n",
    "        return pd.get_dummies(self.data[\"頻度\"]).astype(int)\n",
    "\n",
    "    def encode_tsu(self):\n",
    "        return pd.get_dummies(self.data[\"使い道\"]).astype(int)\n",
    "\n",
    "    def encode_denpou(self):\n",
    "        # cate = self.data[\"店舗名\"].to_frame()\n",
    "        # le = LabelEncoder()\n",
    "        # a = le.fit_transform(cate).flatten()\n",
    "        # return pd.DataFrame({\"denpou\":a})\n",
    "        self.features['denpo'] = self.data['店舗名'].map(self.data['店舗名'].value_counts()).to_numpy()\n",
    "\n",
    "    def encode_goods(self):\n",
    "        self.features['goods'] = self.data['商品名'].map(self.data['商品名'].value_counts()).to_numpy()\n",
    "\n",
    "    def encode_users(self):\n",
    "        self.features['user'] = self.data['投稿者ID'].map(self.data['投稿者ID'].value_counts()).to_numpy()\n",
    "\n",
    "    def encode_genre(self):\n",
    "        self.features['商品ジャンルID'] = self.data['商品ジャンルID'].map(self.data['商品ジャンルID'].value_counts()).to_numpy()\n",
    "\n",
    "    def get_y(self,cut_off:int):\n",
    "        out = self.data[\"参考になった数\"].to_numpy()\n",
    "        return np.where(out > cut_off, 1, 0)\n",
    "\n",
    "    def to_frame(self):\n",
    "        # self.date_feature()\n",
    "        self.word_count() #单词数\n",
    "        self.title_wc() #标题单词数\n",
    "        self.is_title() #是否有标题\n",
    "        self.is_mokuteki() #目的\n",
    "        self.is_ti() #使い道\n",
    "        self.is_hin() #頻度\n",
    "        self.score() #评论分数\n",
    "        self.encode_goods() #商品名\n",
    "        self.encode_users() #用户\n",
    "        self.encode_genre() #类别\n",
    "        self.encode_denpou() #店铺\n",
    "        encoded_hindo = self.encode_hindo() #使用频度\n",
    "        encoded_mokuteki = self.encode_mokuteki() #使用目的\n",
    "        encoded_tsu = self.encode_tsu() #使用方法\n",
    "\n",
    "\n",
    "        data = pd.DataFrame(self.features)\n",
    "        data = pd.concat([data, encoded_mokuteki,encoded_hindo, encoded_tsu, encoded_tsu], axis = 1)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7076"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = Feature_extractor(\"/home/hc/[NII-IDR] 楽天市場データ/review/sample/sample_from_raw.csv\")\n",
    "len(extractor.data['商品ジャンルID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Feature_extractor(\"/home/hc/[NII-IDR] 楽天市場データ/review/sample/sample_from_raw.csv\")\n",
    "y = extractor.get_y(cut_off=5)\n",
    "X = extractor.to_frame()\n",
    "# scalar = MinMaxScaler()\n",
    "# X = scalar.fit_transform(X)\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11764706, 0.18954248, 0.16339869, 0.16883117, 0.13636364])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=False) #分层抽样，保持每个样本中每个class的比例相同\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote_pipeline = make_pipeline(SMOTE(random_state=42),\n",
    "                              RandomForestClassifier(n_estimators=100, random_state=13))\n",
    "cross_val_score(smote_pipeline, X_train, Y_train, scoring='recall', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    139233\n",
       "1       767\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_train).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
