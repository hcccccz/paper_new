{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mecab-python3\n",
        "!pip install unidic-lite\n",
        "!pip install ipadic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvA1Sx7scN96",
        "outputId": "713a39eb-2009-41e0-bb14-29a924ecb2c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mecab-python3\n",
            "  Downloading mecab_python3-1.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Downloading mecab_python3-1.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.7/581.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-1.0.9\n",
            "Collecting unidic-lite\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unidic-lite\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=6b9e9014c600bf828a0c09dcff1c0da66e91aebcbee51f86802a425a48d106f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "Successfully built unidic-lite\n",
            "Installing collected packages: unidic-lite\n",
            "Successfully installed unidic-lite-1.0.8\n",
            "Collecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=4b80b00d4c0b3dece57c42b06177b36c86d2d404e2f7a27072b9c05592bc0d7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "Successfully built ipadic\n",
            "Installing collected packages: ipadic\n",
            "Successfully installed ipadic-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmdzQjnzb6R2",
        "outputId": "880571bf-923d-46d6-cd7d-2d231ac52779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import MeCab\n",
        "import ipadic\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/MyDrive/data/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UartB430cnpq",
        "outputId": "8e796388-1980-472f-bf8d-645452be792f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unzip', 'sample']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KsIx9jR5b6R2"
      },
      "outputs": [],
      "source": [
        "sample_path = \"/content/drive/MyDrive/data/sample\"\n",
        "unzip_path = \"/content/drive/MyDrive/data/unzip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPz3u0oTb6R2"
      },
      "source": [
        "### Generate Wakati reviview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KKlKgUDb6R3"
      },
      "outputs": [],
      "source": [
        "wakati = MeCab.Tagger(\"-Owakati\")\n",
        "data_sub = pd.read_csv(sample_path)['レビュー内容']\n",
        "text = data_sub.to_numpy()\n",
        "with open(\"wakati_review.txt\", \"w\") as fp:\n",
        "    for line in tqdm(text):\n",
        "        fp.write(wakati.parse(line))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v75FgsZrb6R3"
      },
      "source": [
        "### Randomly print a review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Y6OWyS07b6R3",
        "outputId": "ea85d8db-affa-4438-ca5f-dd630de500a4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content/drive/MyDrive/data/sample'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-448b4bcfb8ea>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdata_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'レビュー内容'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/drive/MyDrive/data/sample'"
          ]
        }
      ],
      "source": [
        "CHASEN_ARGS = r' -F \"%m\\t%f[7]\\t%f[6]\\t%F-[0,1,2,3]\\t%f[4]\\t%f[5]\\n\"'\n",
        "CHASEN_ARGS += r' -U \"%m\\t%m\\t%m\\t%F-[0,1,2,3]\\t\\t\\n\"'\n",
        "\n",
        "wakati = MeCab.Tagger(ipadic.MECAB_ARGS + CHASEN_ARGS)\n",
        "\n",
        "\n",
        "data = pd.read_csv(sample_path)\n",
        "data_sub = data['レビュー内容'].to_numpy()\n",
        "select = np.random.choice(data_sub)\n",
        "results = wakati.parse(select)\n",
        "print(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4LOaO4Sb6R3"
      },
      "source": [
        "### Sampler class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CpsCoeDBb6R3"
      },
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "\n",
        "    def __init__(self,path,data_saved, sample_size):\n",
        "        self.path = path #path to raw\n",
        "        self.data_saved = data_saved\n",
        "        if not os.path.isdir(self.data_saved):\n",
        "            os.mkdir(self.data_saved)\n",
        "        self.encoded_out_dir = os.path.join(self.data_saved,\"file_encoded.txt\")\n",
        "        self.sample_index_outdir = os.path.join(self.data_saved,\"file_sample.txt\")\n",
        "        self.sample_csv_out_dir = os.path.join(self.data_saved,\"sample_from_raw.csv\")\n",
        "        self.sample_size = sample_size\n",
        "\n",
        "    def file_encode(self):\n",
        "        \"\"\"\n",
        "        读取所有的评论,将index和参考になった数存下来保存到out_name文件下\"\"\"\n",
        "\n",
        "        self.file_list = sorted(os.listdir(self.path)) #列出所以文件\n",
        "        with open(self.encoded_out_dir, \"w\") as file: #file_encoded.txt\n",
        "            for file_name in tqdm(self.file_list):\n",
        "                data = pd.read_csv(os.path.join(self.path,file_name),sep='\\t',quoting=csv.QUOTE_NONE)\n",
        "                col = ['投稿者ID', '店舗名', '店舗ID', '商品名', '商品ID', '商品ページURL', '商品ジャンルID', '商品ジャンルIDパス', '使い道',\n",
        "                        '目的', '頻度', '評価ポイント', 'レビュータイトル', 'レビュー内容', '参考になった数', 'レビュー登録日時']\n",
        "                data.columns = col\n",
        "                data.reset_index(inplace=True) #add index column\n",
        "                data = data[[\"index\",\"参考になった数\"]].to_numpy()\n",
        "                for line in range(data.shape[0]):\n",
        "                    content = file_name + \" \" + \" \".join(str(i) for i in data[line,:].tolist())\n",
        "                    file.write(content + \"\\n\")\n",
        "\n",
        "    def sample_file(self):\n",
        "        path_to_encoded = self.encoded_out_dir\n",
        "        path_to_sample = self.sample_index_outdir\n",
        "        if not os.path.exists(path_to_encoded):\n",
        "            self.file_encode()\n",
        "        else:\n",
        "            print(\"encoded exist\")\n",
        "            with open(path_to_encoded,\"r\") as file:\n",
        "                encoded = file.readlines()\n",
        "\n",
        "            sample = np.random.choice(range(len(encoded)),size=self.sample_size, replace=False)\n",
        "            encoded_sample = [encoded[i] for i in sample] #slicing wit list of index\n",
        "        with open(path_to_sample,\"w\") as file:\n",
        "            for line in encoded_sample:\n",
        "                file.write(line)\n",
        "\n",
        "    def entry_from_row(self):\n",
        "        path_to_sample = self.sample_index_outdir\n",
        "        if not os.path.exists(path_to_sample):\n",
        "            self.sample_file()\n",
        "        else:\n",
        "            print(\"sample file exist\")\n",
        "            with open(path_to_sample, \"r\") as file:\n",
        "                sample = {}\n",
        "                for line in file:\n",
        "                    line = line.replace(\"\\n\", \"\").split(\" \")\n",
        "                    line_index = sample.setdefault(line[0],[]) #key is file name, value is list of index\n",
        "                    line_index.append(line[1])\n",
        "            frames = []\n",
        "            print(\"start to sampling\")\n",
        "            for key in tqdm(sample.keys()):\n",
        "                path = os.path.join(self.path,key)\n",
        "                df = pd.read_csv(path,sep='\\t',quoting=csv.QUOTE_NONE)\n",
        "                col = ['投稿者ID', '店舗名', '店舗ID', '商品名', '商品ID', '商品ページURL', '商品ジャンルID', '商品ジャンルIDパス', '使い道',\n",
        "                        '目的', '頻度', '評価ポイント', 'レビュータイトル', 'レビュー内容', '参考になった数', 'レビュー登録日時']\n",
        "                df.columns = col\n",
        "                df.reset_index(inplace=True)\n",
        "                idxs = [int(idx) for idx in sample[key]]\n",
        "                frame = df.iloc[idxs,:].copy()\n",
        "                frames.append(frame)\n",
        "            result = pd.concat(frames)\n",
        "            result.reset_index(inplace=True)\n",
        "            result.to_csv(self.sample_csv_out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf1ckkedb6R4"
      },
      "source": [
        "### Extract Hinshi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtJE3R31b6R4"
      },
      "outputs": [],
      "source": [
        "def extract_hinshi(text, hinshi:str):\n",
        "    \"\"\"\n",
        "    品词, 抽出所有文本对应的品词 text 为pandas review dataframe to numpy。 返回text中所以对应的hinshi\n",
        "    \"\"\"\n",
        "    wakati = MeCab.Tagger(ipadic.MECAB_ARGS + CHASEN_ARGS)\n",
        "    kigo = set()\n",
        "    CHASEN_ARGS = r' -F \"%m\\t%f[7]\\t%f[6]\\t%F-[0,1,2,3]\\t%f[4]\\t%f[5]\\n\"'\n",
        "    CHASEN_ARGS += r' -U \"%m\\t%m\\t%m\\t%F-[0,1,2,3]\\t\\t\\n\"'\n",
        "\n",
        "    for line in text:\n",
        "        for token in wakati_text:\n",
        "            token = token.split(\"\\t\")\n",
        "            if token[0] != \"\" and token[0] != \"EOS\":\n",
        "                if hinshi in token[3]:\n",
        "                    kigo.add(token[0])\n",
        "    return kigo\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "ozXVibe2d0Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = Sampler(path=unzip_path, data_saved= sample_path, sample_size=50000)\n",
        "sampler"
      ],
      "metadata": {
        "id": "ukSEd0PbcCnZ"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}