{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mecab-python3\n",
        "!pip install unidic-lite\n",
        "!pip install ipadic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvA1Sx7scN96",
        "outputId": "72aeacea-f35c-480d-fe3e-57934ec8e4b5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: unidic-lite in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmdzQjnzb6R2",
        "outputId": "b175c183-4731-458b-839e-1a198b34d242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import MeCab\n",
        "import ipadic\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/MyDrive/data/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UartB430cnpq",
        "outputId": "d42c0ba5-02fd-4db0-dec4-94e8cf8e12e6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unzip', 'sample']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KsIx9jR5b6R2"
      },
      "outputs": [],
      "source": [
        "sample_path = \"/content/drive/MyDrive/data/sample\"\n",
        "unzip_path = \"/content/drive/MyDrive/data/unzip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPz3u0oTb6R2"
      },
      "source": [
        "### Generate Wakati reviview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KKlKgUDb6R3"
      },
      "outputs": [],
      "source": [
        "wakati = MeCab.Tagger(\"-Owakati\")\n",
        "data_sub = pd.read_csv(sample_path)['レビュー内容']\n",
        "text = data_sub.to_numpy()\n",
        "with open(\"wakati_review.txt\", \"w\") as fp:\n",
        "    for line in tqdm(text):\n",
        "        fp.write(wakati.parse(line))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v75FgsZrb6R3"
      },
      "source": [
        "### Randomly print a review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Y6OWyS07b6R3",
        "outputId": "ea85d8db-affa-4438-ca5f-dd630de500a4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content/drive/MyDrive/data/sample'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-448b4bcfb8ea>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdata_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'レビュー内容'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/drive/MyDrive/data/sample'"
          ]
        }
      ],
      "source": [
        "CHASEN_ARGS = r' -F \"%m\\t%f[7]\\t%f[6]\\t%F-[0,1,2,3]\\t%f[4]\\t%f[5]\\n\"'\n",
        "CHASEN_ARGS += r' -U \"%m\\t%m\\t%m\\t%F-[0,1,2,3]\\t\\t\\n\"'\n",
        "\n",
        "wakati = MeCab.Tagger(ipadic.MECAB_ARGS + CHASEN_ARGS)\n",
        "\n",
        "\n",
        "data = pd.read_csv(sample_path)\n",
        "data_sub = data['レビュー内容'].to_numpy()\n",
        "select = np.random.choice(data_sub)\n",
        "results = wakati.parse(select)\n",
        "print(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4LOaO4Sb6R3"
      },
      "source": [
        "### Sampler class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CpsCoeDBb6R3"
      },
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "\n",
        "    def __init__(self,path,data_saved, sample_size):\n",
        "        self.path = path #path to raw\n",
        "        self.data_saved = data_saved\n",
        "        if not os.path.isdir(self.data_saved):\n",
        "            os.mkdir(self.data_saved)\n",
        "        self.encoded_out_dir = os.path.join(self.data_saved,\"file_encoded.txt\")\n",
        "        self.sample_index_outdir = os.path.join(self.data_saved,\"file_sample.txt\")\n",
        "        self.sample_csv_out_dir = os.path.join(self.data_saved,\"sample_from_raw.csv\")\n",
        "        self.sample_size = sample_size\n",
        "\n",
        "    def file_encode(self):\n",
        "        \"\"\"\n",
        "        读取所有的评论,将index和参考になった数存下来保存到out_name文件下\"\"\"\n",
        "\n",
        "        self.file_list = sorted(os.listdir(self.path)) #列出所以文件\n",
        "        with open(self.encoded_out_dir, \"w\") as file: #file_encoded.txt\n",
        "            for file_name in tqdm(self.file_list):\n",
        "                data = pd.read_csv(os.path.join(self.path,file_name),sep='\\t',quoting=csv.QUOTE_NONE)\n",
        "                col = ['投稿者ID', '店舗名', '店舗ID', '商品名', '商品ID', '商品ページURL', '商品ジャンルID', '商品ジャンルIDパス', '使い道',\n",
        "                        '目的', '頻度', '評価ポイント', 'レビュータイトル', 'レビュー内容', '参考になった数', 'レビュー登録日時']\n",
        "                data.columns = col\n",
        "                data.reset_index(inplace=True) #add index column\n",
        "                data = data[[\"index\",\"参考になった数\"]].to_numpy()\n",
        "                for line in range(data.shape[0]):\n",
        "                    content = file_name + \" \" + \" \".join(str(i) for i in data[line,:].tolist())\n",
        "                    file.write(content + \"\\n\")\n",
        "\n",
        "    def sample_file(self):\n",
        "        path_to_encoded = self.encoded_out_dir\n",
        "        path_to_sample = self.sample_index_outdir\n",
        "        if not os.path.exists(path_to_encoded):\n",
        "            self.file_encode()\n",
        "        else:\n",
        "            print(\"encoded exist\")\n",
        "            with open(path_to_encoded,\"r\") as file:\n",
        "                encoded = file.readlines()\n",
        "\n",
        "            sample = np.random.choice(range(len(encoded)),size=self.sample_size, replace=False)\n",
        "            encoded_sample = [encoded[i] for i in sample] #slicing wit list of index\n",
        "            with open(path_to_sample,\"w\") as file:\n",
        "                for line in encoded_sample:\n",
        "                    file.write(line)\n",
        "\n",
        "    def entry_from_row(self):\n",
        "        path_to_sample = self.sample_index_outdir\n",
        "        if not os.path.exists(path_to_sample):\n",
        "            self.sample_file()\n",
        "        else:\n",
        "            print(\"sample file exist\")\n",
        "            with open(path_to_sample, \"r\") as file:\n",
        "                sample = {}\n",
        "                for line in file:\n",
        "                    line = line.replace(\"\\n\", \"\").split(\" \")\n",
        "                    line_index = sample.setdefault(line[0],[]) #key is file name, value is list of index\n",
        "                    line_index.append(line[1])\n",
        "            frames = []\n",
        "            print(\"start to sampling\")\n",
        "            for key in tqdm(sample.keys()):\n",
        "                path = os.path.join(self.path,key)\n",
        "                df = pd.read_csv(path,sep='\\t',quoting=csv.QUOTE_NONE)\n",
        "                col = ['投稿者ID', '店舗名', '店舗ID', '商品名', '商品ID', '商品ページURL', '商品ジャンルID', '商品ジャンルIDパス', '使い道',\n",
        "                        '目的', '頻度', '評価ポイント', 'レビュータイトル', 'レビュー内容', '参考になった数', 'レビュー登録日時']\n",
        "                df.columns = col\n",
        "                df.reset_index(inplace=True)\n",
        "                idxs = [int(idx) for idx in sample[key]]\n",
        "                frame = df.iloc[idxs,:].copy()\n",
        "                frames.append(frame)\n",
        "            result = pd.concat(frames)\n",
        "            result.reset_index(inplace=True)\n",
        "            result.to_csv(self.sample_csv_out_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf1ckkedb6R4"
      },
      "source": [
        "### Extract Hinshi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtJE3R31b6R4"
      },
      "outputs": [],
      "source": [
        "def extract_hinshi(text, hinshi:str):\n",
        "    \"\"\"\n",
        "    品词, 抽出所有文本对应的品词 text 为pandas review dataframe to numpy。 返回text中所以对应的hinshi\n",
        "    \"\"\"\n",
        "    wakati = MeCab.Tagger(ipadic.MECAB_ARGS + CHASEN_ARGS)\n",
        "    kigo = set()\n",
        "    CHASEN_ARGS = r' -F \"%m\\t%f[7]\\t%f[6]\\t%F-[0,1,2,3]\\t%f[4]\\t%f[5]\\n\"'\n",
        "    CHASEN_ARGS += r' -U \"%m\\t%m\\t%m\\t%F-[0,1,2,3]\\t\\t\\n\"'\n",
        "\n",
        "    for line in text:\n",
        "        for token in wakati_text:\n",
        "            token = token.split(\"\\t\")\n",
        "            if token[0] != \"\" and token[0] != \"EOS\":\n",
        "                if hinshi in token[3]:\n",
        "                    kigo.add(token[0])\n",
        "    return kigo\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "ozXVibe2d0Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = Sampler(path=unzip_path, data_saved= sample_path, sample_size=50000)\n",
        "sampler.entry_from_row()"
      ],
      "metadata": {
        "id": "ukSEd0PbcCnZ",
        "outputId": "fd839953-6598-4cee-d277-d60d329e60cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [34:46<00:00, 34.78s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'encoded_sample' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-45f5b4572f8e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_saved\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msample_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_from_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-5487979e549d>\u001b[0m in \u001b[0;36mentry_from_row\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mpath_to_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_index_outdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample file exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-5487979e549d>\u001b[0m in \u001b[0;36msample_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mencoded_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#slicing wit list of index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'encoded_sample' referenced before assignment"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}